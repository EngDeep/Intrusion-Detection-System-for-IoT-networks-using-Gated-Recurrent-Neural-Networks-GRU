{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing all the required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoading and pre-processing:\n",
    "\n",
    "Functions defined for Data Loading and Data Pre-processing\n",
    "\n",
    "DataLoading - Loads the csv data into the system\n",
    "\n",
    "DataPreprocessing - Performs below operations on the loaded dataset\n",
    "                    \n",
    "                    1) Dropping the Duplicates\n",
    "                   \n",
    "                    2) Dividing the dataset into features set and the labels set\n",
    "                    \n",
    "                    3) Converting catergoial data into numerical data\n",
    "                    \n",
    "                    4) Encoding the normal as '1' and abnormal as '0'\n",
    "                    \n",
    "                    5) converting input data into float which is requried in the future stage of building \n",
    "                        in the network\n",
    "                    \n",
    "                    6) Adding another column to the labels set - kind of one hot encoding\n",
    "                    \n",
    "                        i.e normal = '1' is represented as '1 0'\n",
    "                    \n",
    "                        abnormal = '0' is represented as '0 1'\n",
    "                    \n",
    "                        This is required so that the softmax entropy function can efficiently\n",
    "                        calculate the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataLoading (mypath):\n",
    "    print (\"Loading the data\")\n",
    "    dataframe = pd.read_csv(mypath,header = None,engine = 'python',sep=\",\")\n",
    "    return dataframe\n",
    "\n",
    "def DataPreprocessing(mydataframe):\n",
    "    \n",
    "    # Dropping the duplicates\n",
    "    recordcount = len(mydataframe)\n",
    "    print (\"Original number of records in the training dataset before removing duplicates is: \" , recordcount)\n",
    "    mydataframe.drop_duplicates(subset=None, inplace=True)  # Python command to drop duplicates\n",
    "    newrecordcount = len(mydataframe)\n",
    "    print (\"Number of records in the training dataset after removing the duplicates is :\", newrecordcount,\"\\n\")\n",
    "\n",
    "    #Dropping the labels to a different dataset which is used to train the recurrent neural network classifier\n",
    "    df_X = mydataframe.drop(mydataframe.columns[41],axis=1,inplace = False)\n",
    "    df_Y = mydataframe.drop(mydataframe.columns[0:41],axis=1, inplace = False)\n",
    "\n",
    "    # Convert Categorial data to the numerical data for the efficient classification\n",
    "    df_X[df_X.columns[1:4]] = df_X[df_X.columns[1:4]].stack().rank(method='dense').unstack()\n",
    "    \n",
    "    # Coding the normal as \" 1 0\" and attack as \"0 1\"\n",
    "    df_Y[df_Y[41]!='normal.'] = 0\n",
    "    df_Y[df_Y[41]=='normal.'] = 1\n",
    "    #print (labels[41].value_counts())\n",
    "    \n",
    "    #converting input data into float which is requried in the future stage of building in the network\n",
    "    df_X = df_X.loc[:,df_X.columns[0:41]].astype(float)\n",
    "\n",
    "    # Normal is \"1 0\" and the abnormal is \"0 1\"\n",
    "    df_Y.columns = [\"y1\"]\n",
    "    df_Y.loc[:,('y2')] = df_Y['y1'] ==0\n",
    "    df_Y.loc[:,('y2')] = df_Y['y2'].astype(int)\n",
    "    \n",
    "\n",
    "    \n",
    "    return df_X,df_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection:\n",
    "\n",
    "The below function is for the feature selection. RandomForest Classifier is used to select features with top ranks\n",
    "\n",
    "RandomforestClassifier: Evaluates the importance of the features and plotting features vs importances\n",
    "Selecting the features with \"higher importance\" are relevant for the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FeatureSelection(myinputX, myinputY):\n",
    "\n",
    "    labels = np.array(myinputY).astype(int)\n",
    "    inputX = np.array(myinputX)\n",
    "    \n",
    "    #Random Forest Model\n",
    "    model = RandomForestClassifier(random_state = 0)\n",
    "    model.fit(inputX,labels)\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    \n",
    "    #Plotting the Features agains their importance scores\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "    plt.figure(figsize = (10,5))\n",
    "    plt.title(\"Feature importances (y-axis) vs Features IDs(x-axis)\")\n",
    "    plt.bar(range(inputX.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(inputX.shape[1]), indices)\n",
    "    plt.xlim([-1, inputX.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    # Selecting top featueres which have higher importance values = here we can find \"12\" features\n",
    "    #as we can see in the next step\n",
    "    newX = myinputX.iloc[:,model.feature_importances_.argsort()[::-1][:12]]\n",
    "   # Converting the X dataframe into tensors\n",
    "    myX = newX.as_matrix()\n",
    "    myY = labels\n",
    "\n",
    "   \n",
    "    return myX,myY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data into the system\n",
    "\n",
    "And applying the data preprocessing and feature selection for the dataset\n",
    "\n",
    "Divinding into train and test datasets \n",
    "\n",
    "Performing the above operations are required before training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laoding the IDS Data\n",
      "Loading the data\n",
      "Data Preprocessing of loaded IDS Data\n",
      "Original number of records in the training dataset before removing duplicates is:  13200\n",
      "Number of records in the training dataset after removing the duplicates is : 13051 \n",
      "\n",
      "Performing the Feature Selection on train data set\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAE/CAYAAACEto0QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDFaSJEmNGKwkSZIaMVhJkiQ18v8BInsKvWUpYHEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac54bf0240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape is : (8000, 6)\n",
      "Train Y shape is : (8000, 2)\n",
      "Test X shape is : (1999, 6)\n",
      "Test Y shape is : (1999, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"Laoding the IDS Data\")\n",
    "data_path = \"C:/Users/manp/Documents/IoT/Final/ApplicationLayer/ApplicationLayer.txt\"\n",
    "dataframe = DataLoading(data_path)\n",
    "\n",
    "print (\"Data Preprocessing of loaded IDS Data\")\n",
    "data_X, data_Y = DataPreprocessing(dataframe)\n",
    "\n",
    "print (\"Performing the Feature Selection on train data set\")\n",
    "reduced_X,reduced_Y = FeatureSelection(data_X,data_Y)\n",
    "\n",
    "#Dividing the dataset into train and test datasets\n",
    "# Out of 13051 samples = 80% samples as train data and 20% samples as test data\n",
    "\n",
    "# Train features and Train Labels\n",
    "train_X = reduced_X[:8000]\n",
    "train_Y = reduced_Y[:8000]\n",
    "\n",
    "#Test Features and Test Labels\n",
    "test_X = reduced_X[8001:10000]\n",
    "test_Y = reduced_Y[8001:10000]\n",
    "\n",
    "\n",
    "print (\"Train X shape is :\", train_X.shape)\n",
    "print (\"Train Y shape is :\", train_Y.shape)\n",
    "print (\"Test X shape is :\", test_X.shape)\n",
    "print (\"Test Y shape is :\", test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the above features importance graph, the below features are highly informative\n",
    "\n",
    "4,32,1,39,2,34,23,33,35,5,9,36\n",
    "\n",
    "The features are reduced from 40 to 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Input Features\n",
    "Using tensorflow normalizing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before normalizing, the array of input features should be converted to a dataframe\n",
    "semitrain_X = pd.DataFrame(train_X)\n",
    "semitest_X = pd.DataFrame(test_X)\n",
    "#Importing Scikit learn libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "#Normalizing Train Data Features\n",
    "scaler_traindata = scaler.fit(semitrain_X)\n",
    "train_norm = scaler_traindata.transform(semitrain_X)\n",
    "train_norm_X = pd.DataFrame(train_norm)\n",
    "\n",
    "#Normalizing Test Data Features\n",
    "scaler_testdata = scaler.fit(semitest_X)\n",
    "test_norm = scaler_testdata.transform(semitest_X)\n",
    "test_norm_X = pd.DataFrame(test_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Paramteres and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Hyper Parameters for the model\n",
    "learning_rate = 0.001\n",
    "n_classes = 2\n",
    "display_step = 100\n",
    "input_features = train_X.shape[1] #No of selected features(columns)\n",
    "training_cycles = 1000\n",
    "time_steps = 5 # No of time-steps to backpropogate\n",
    "hidden_units = 50 #No of LSTM units in a LSTM Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Placeholders takes the inputs for the model in the shape [inputs_size,input_features]\n",
    "\n",
    "Here we are not restricting the input size, therefore it batch_size is given as \"None\"\n",
    "\n",
    "Weights and biases are initialized in random using tf.random_normal function\n",
    "\n",
    "Sizes are defined appropritately as per the logic.\n",
    "\n",
    "The biases output either '1 0' or '0 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input Placeholders\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float64,shape = [None,time_steps,input_features], name = \"x-input\")\n",
    "    y = tf.placeholder(tf.float64, shape = [None,n_classes],name = \"y-input\")\n",
    "#Weights and Biases\n",
    "with tf.name_scope(\"weights\"):\n",
    "    W = tf.Variable(tf.random_normal([hidden_units,n_classes]),name = \"layer-weights\")\n",
    "\n",
    "with tf.name_scope(\"biases\"):\n",
    "    b = tf.Variable(tf.random_normal([n_classes]),name = \"unit-biases\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](C:/Users/manp/Desktop/Capture.PNG)\n",
    "\n",
    "The above image is a sample diagram portraying the back propogation.\n",
    "In our model,\n",
    "the Input is a 3D-Tensor of size (Batch_Size,Time_Steps,Num_Features)\n",
    "Only One hidden layer is used to design a lightweight model - Hidden Layer Size (LSTM Units = 10)\n",
    "Weights Size (Hidden_units,Num_Classes)\n",
    "Biases Size (Num_Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before bulding the model, we have to reshape the inputs in to 3D tensors of size (Batch_Size,time_steps,input_features)\n",
    "from 2D tensors of size (Batch_Size,input_features). As seen in the above placeholder description, it accepts \n",
    "3D inputs.\n",
    "\n",
    "This can be done as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new train X (7995, 5, 6)\n",
      "Shape of new train Y (7995, 2)\n",
      "Shape of new test X (1994, 5, 6)\n",
      "Shape of new test Y (1994, 2)\n"
     ]
    }
   ],
   "source": [
    "#Modify data with respect to the time steps count\n",
    "def rnn_data(data, time_steps, labels=False):\n",
    "    \"\"\"\n",
    "    creates new data frame based on previous observation\n",
    "      * example:\n",
    "        l = [1, 2, 3, 4, 5]\n",
    "        time_steps = 2\n",
    "        -> labels == False [[1, 2], [2, 3], [3, 4]]\n",
    "        -> labels == True [3, 4, 5]\n",
    "    \"\"\"\n",
    "    rnn_df = []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        if labels:\n",
    "            try:\n",
    "                rnn_df.append(data.iloc[i + time_steps].as_matrix())\n",
    "            except AttributeError:\n",
    "                rnn_df.append(data.iloc[i + time_steps])\n",
    "        else:\n",
    "            data_ = data.iloc[i: i + time_steps].as_matrix()\n",
    "            rnn_df.append(data_ if len(data_.shape) > 1 else [[i] for i in data_])\n",
    "\n",
    "    return np.array(rnn_df, dtype=np.float32)\n",
    "\n",
    "# Modifications to train data\n",
    "train_data_X = pd.DataFrame(train_norm_X)\n",
    "train_data_Y = pd.DataFrame(train_Y)\n",
    "newtrain_X = rnn_data(train_data_X,time_steps,labels = False)\n",
    "newtrain_Y = rnn_data(train_data_Y,time_steps,labels = True)\n",
    "\n",
    "print (\"Shape of new train X\",newtrain_X.shape)\n",
    "print (\"Shape of new train Y\",newtrain_Y.shape)\n",
    "\n",
    "# Modifications to test data\n",
    "test_data_X = pd.DataFrame(test_norm_X)\n",
    "test_data_Y = pd.DataFrame(test_Y)\n",
    "newtest_X = rnn_data(test_data_X,time_steps,labels = False)\n",
    "newtest_Y = rnn_data(test_data_Y,time_steps,labels = True)\n",
    "\n",
    "print (\"Shape of new test X\",newtest_X.shape)\n",
    "print (\"Shape of new test Y\",newtest_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unstacking the inputs with time steps to provide the inputs in sequence\n",
    "# Unstack to get a list of 'time_steps' tensors of shape (batch_size, input_features)\n",
    "x_ = tf.unstack(x,time_steps,axis =1)\n",
    "\n",
    "#Defining a single GRU cell\n",
    "gru_cell = tf.contrib.rnn.GRUCell(hidden_units)\n",
    "\n",
    "#GRU Output\n",
    "with tf.variable_scope('MyGRUCel36'):\n",
    "    gruoutputs,grustates = tf.contrib.rnn.static_rnn(gru_cell,x_,dtype=tf.float64)\n",
    "    \n",
    "#Linear Activation , using gru inner loop last output\n",
    "output =  tf.add(tf.matmul(gruoutputs[-1],tf.cast(W,tf.float64)),tf.cast(b,tf.float64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a loss function just as easily. \n",
    "Loss indicates how bad the model's prediction was on a single example; \n",
    "we try to minimize that while training across all the examples. \n",
    "Here, our loss function is the cross-entropy between the target \n",
    "and the softmax activation function applied to the model's prediction.\n",
    "\n",
    "Note that tf.nn.softmax_cross_entropy_with_logits internally applies the softmax on the model's \n",
    "unnormalized model prediction and sums across \n",
    "all classes, and tf.reduce_mean takes the average over these sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the loss function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits = output))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.train.AdamOptimizer uses Kingma and Ba's Adam algorithm to control the learning rate. \n",
    "Adam offers several advantages over the simple tf.train.GradientDescentOptimizer. \n",
    "Foremost is that it uses moving averages of the parameters (momentum)\n",
    "\n",
    "A simple tf.train.GradientDescentOptimizer could equally be used in your model, but would require more hyperparameter \n",
    "tuning before it would converge as quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for the training cycle :  0  : is :  1.49658893849\n",
      "Cost for the training cycle :  100  : is :  0.693460223534\n",
      "Cost for the training cycle :  200  : is :  0.689997076673\n",
      "Cost for the training cycle :  300  : is :  0.688120609282\n",
      "Cost for the training cycle :  400  : is :  0.687008004355\n",
      "Cost for the training cycle :  500  : is :  0.686129875029\n",
      "Cost for the training cycle :  600  : is :  0.685329069629\n",
      "Cost for the training cycle :  700  : is :  0.68456846978\n",
      "Cost for the training cycle :  800  : is :  0.683825161497\n",
      "Cost for the training cycle :  900  : is :  0.683055802148\n",
      "Accuracy on the overall test set is : 0.535105\n"
     ]
    }
   ],
   "source": [
    "#Training the Model\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range (training_cycles):\n",
    "    _,c = sess.run([optimizer,cost], feed_dict = {x:newtrain_X, y:newtrain_Y})\n",
    "    \n",
    "    if (i) % display_step == 0:\n",
    "        print (\"Cost for the training cycle : \",i,\" : is : \",sess.run(cost, feed_dict ={x :newtrain_X,y:newtrain_Y}))\n",
    "correct = tf.equal(tf.argmax(output, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "print('Accuracy on the overall test set is :',accuracy.eval({x:newtest_X, y:newtest_Y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix \n",
      " [[13  8]\n",
      " [11  3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEQCAYAAADmsCy1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1PTfL94+ACSxDBUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac5485f898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tf.argmax = Returns the index with the largest value across axes of a tensor.\n",
    "# Therefore, we are extracting the final labels => '1 0' = '1' = Normal (and vice versa)\n",
    "# Steps to calculate the confusion matrix\n",
    "\n",
    "pred_class = sess.run(tf.argmax(output,1),feed_dict = {x:newtest_X,y:newtest_Y})\n",
    "labels_class = sess.run(tf.argmax(y,1),feed_dict = {x:newtest_X,y:newtest_Y})\n",
    "conf = tf.contrib.metrics.confusion_matrix(labels_class,pred_class,dtype = tf.int32)\n",
    "ConfM = sess.run(conf, feed_dict={x:newtest_X,y:newtest_Y})\n",
    "print (\"confusion matrix \\n\",ConfM)\n",
    "\n",
    "#Plotting the Confusion Matrix\n",
    "labels = ['Normal', 'Attack']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(ConfM)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy calcualted using tf.contrib 0.632387\n",
      "Accuracy calculated manually through confusion matrix 0.632386799693\n",
      "Precision \n",
      " 0.320754716981\n",
      "Recall (DR) - Sensitivity [True Positive Rate]\n",
      " 0.0369565217391\n",
      "Specificity \n",
      " 0.957295373665\n",
      "F1 Score is \n",
      " 0.0662768031189\n",
      "False Alarm Rate also known as False Positive Rate \n",
      " 0.0427046263345\n",
      "Efficincy is \n",
      " 0.865398550725\n"
     ]
    }
   ],
   "source": [
    "# Calculating Accuracy through another procedure\n",
    "n = tf.cast(labels_class,tf.int64)\n",
    "newaccuracy = tf.contrib.metrics.accuracy(pred_class,n)\n",
    "print (\"accuracy calcualted using tf.contrib\", sess.run (newaccuracy, feed_dict = {x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Calculations performed manually for other metrics\n",
    "TP = conf[0,0]\n",
    "FN = conf [0,1]\n",
    "FP = conf[1,0]\n",
    "TN = conf[1,1]\n",
    "\n",
    "AccConf = (TP+TN)/(TP+FP+TN+FN)\n",
    "print (\"Accuracy calculated manually through confusion matrix\", sess.run (AccConf, feed_dict = {x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "# Precision\n",
    "Precision = TP/(TP+FP)\n",
    "print (\"Precision \\n\",sess.run(Precision,feed_dict ={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Recall also known as Sensitivity\n",
    "Recall = TP/(TP+FN)\n",
    "print (\"Recall (DR) - Sensitivity [True Positive Rate]\\n\", sess.run(Recall,feed_dict={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "# Specificity\n",
    "\n",
    "Specificity = TN/(TN+FP)\n",
    "print (\"Specificity \\n\", sess.run(Specificity,feed_dict={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#F score\n",
    "FScore = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"F1 Score is \\n\",sess.run(FScore,{x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#False Alarm Rate\n",
    "FAR = FP/(FP+TN)\n",
    "print (\"False Alarm Rate also known as False Positive Rate \\n\",sess.run(FAR,feed_dict ={x:newtest_X,y:newtest_Y}))\n",
    "\n",
    "#Efficiency\n",
    "Efficiency = Recall/FAR\n",
    "print(\"Efficincy is \\n\",sess.run(Efficiency,feed_dict = {x:newtest_X,y:newtest_Y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve - True Positive Rate(y-axis) vs False Positive Rate (x-axis) for different thresholds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC describes the discriminative power of a classifier independent of class distribution \n",
    "and unequal prediction error costs (false positive and false negative cost).\n",
    "\n",
    "Metric like accuracy is calculated based on the class distribution of test dataset or cross-validation,\n",
    "but this ratio may change when you apply the classifier to real life data, because the underlying class \n",
    "distribution has been changed or unknown. On the other hand, \n",
    "TP rate and FP rate which are used to construct AUC will be not be affected by class distribution shifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
